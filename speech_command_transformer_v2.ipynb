{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\stt_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.9380\n",
      "Epoch 2/10, Loss: 1.2769\n",
      "Epoch 3/10, Loss: 1.0876\n",
      "Epoch 4/10, Loss: 0.9995\n",
      "Epoch 5/10, Loss: 0.9530\n",
      "Epoch 6/10, Loss: 0.8923\n",
      "Epoch 7/10, Loss: 0.8470\n",
      "Epoch 8/10, Loss: 0.8180\n",
      "Epoch 9/10, Loss: 0.7867\n",
      "Epoch 10/10, Loss: 0.7556\n",
      "Test Accuracy: 80.36%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TORCHAUDIO_BACKEND\"] = \"sox_io\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "\n",
    "# 위치 인코딩 구현\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) *\n",
    "                             (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# SpeechCommands 데이터셋의 서브셋 클래스\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./data\", download=True)\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                return []\n",
    "            with open(filepath) as f:\n",
    "                return [os.path.join(self._path, line.strip()) for line in f]\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "# Transformer 기반 음성 명령 인식 모델\n",
    "class SpeechTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, d_model=128, nhead=8, num_layers=4, \n",
    "                 dim_feedforward=512, dropout=0.1, max_len=5000):\n",
    "        super(SpeechTransformer, self).__init__()\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_targets, all_predictions, average='macro', zero_division=0\n",
    "    )\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 학습 및 평가 실행 함수\n",
    "def run_training_and_evaluation(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs):\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    test_precisions = []\n",
    "    test_recalls = []\n",
    "    test_f1s = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        accuracy, precision, recall, f1 = evaluate_model(model, test_loader)\n",
    "        test_accuracies.append(accuracy)\n",
    "        test_precisions.append(precision)\n",
    "        test_recalls.append(recall)\n",
    "        test_f1s.append(f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, \"\n",
    "              f\"Accuracy: {accuracy*100:.2f}%, Precision: {precision*100:.2f}%, \"\n",
    "              f\"Recall: {recall*100:.2f}%, F1-score: {f1*100:.2f}%\")\n",
    "    return train_losses, test_accuracies, test_precisions, test_recalls, test_f1s\n",
    "\n",
    "# 샘플 데이터 시각화 함수\n",
    "def visualize_samples(dataset, transform, num_samples=5):\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    fig, axs = plt.subplots(num_samples, 2, figsize=(12, 3 * num_samples))\n",
    "    for i, idx in enumerate(indices):\n",
    "        waveform, sr, label, *_ = dataset[idx]\n",
    "        mel_spec = transform(waveform).mean(dim=0)  # 채널 평균\n",
    "        \n",
    "        # 파형 시각화\n",
    "        axs[i, 0].plot(waveform.t().numpy())\n",
    "        axs[i, 0].set_title(f\"Waveform - Label: {label}\")\n",
    "        axs[i, 0].set_xlabel(\"Time\")\n",
    "        axs[i, 0].set_ylabel(\"Amplitude\")\n",
    "        \n",
    "        # Mel-spectrogram 시각화\n",
    "        im = axs[i, 1].imshow(mel_spec.numpy(), origin='lower', aspect='auto', cmap='viridis')\n",
    "        axs[i, 1].set_title(f\"Mel-Spectrogram - Label: {label}\")\n",
    "        axs[i, 1].set_xlabel(\"Time\")\n",
    "        axs[i, 1].set_ylabel(\"Mel Frequency Bin\")\n",
    "        fig.colorbar(im, ax=axs[i, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    transform = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128)\n",
    "    train_set = SubsetSC(\"training\")\n",
    "    test_set = SubsetSC(\"testing\")\n",
    "\n",
    "    # 데이터 시각화: 5개 샘플의 파형, Mel-spectrogram, 라벨 표시\n",
    "    visualize_samples(train_set, transform, num_samples=5)\n",
    "\n",
    "    labels = sorted(list(set(dat[2] for dat in train_set)))\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        waveforms, targets = [], []\n",
    "        for waveform, sample_rate, label, *_ in batch:\n",
    "            mel_spec = transform(waveform).mean(dim=0).transpose(0, 1)\n",
    "            waveforms.append(mel_spec)\n",
    "            targets.append(label_to_idx[label])\n",
    "        waveforms = nn.utils.rnn.pad_sequence(waveforms, batch_first=True)\n",
    "        return waveforms, torch.tensor(targets)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    input_dim = 128\n",
    "    num_classes = len(labels)\n",
    "    model = SpeechTransformer(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    epochs = 10\n",
    "    train_losses, test_accuracies, test_precisions, test_recalls, test_f1s = run_training_and_evaluation(\n",
    "        model, train_loader, test_loader, criterion, optimizer, scheduler, epochs\n",
    "    )\n",
    "\n",
    "    # 시각화: 학습 손실, 정확도, Precision, Recall, F1-score 그래프\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    # 첫 번째 서브플롯: Loss & Accuracy\n",
    "    ax1 = axs[0]\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    ax1.plot(epochs_range, train_losses, color=color, label='Train Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.legend(loc='upper left')\n",
    "\n",
    "    ax1b = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax1b.set_ylabel('Accuracy', color=color)\n",
    "    ax1b.plot(epochs_range, test_accuracies, color=color, label='Test Accuracy')\n",
    "    ax1b.tick_params(axis='y', labelcolor=color)\n",
    "    ax1b.legend(loc='upper right')\n",
    "\n",
    "    # 두 번째 서브플롯: Precision, Recall, F1-score\n",
    "    ax2 = axs[1]\n",
    "    ax2.plot(epochs_range, test_precisions, label='Precision')\n",
    "    ax2.plot(epochs_range, test_recalls, label='Recall')\n",
    "    ax2.plot(epochs_range, test_f1s, label='F1-score')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Precision, Recall, and F1-score over Epochs')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
